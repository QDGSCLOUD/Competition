{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Unet模型\n",
    "import tensorflow as tf \n",
    "\n",
    "def unet(lonpts,latpts,channels=1): \n",
    "    inputs = tf.keras.layers.Input((lonpts,latpts,channels),name='inputs')\n",
    "    conv1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='conv1_1')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='conv1_2')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),name='pool1')(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(64*2, (3, 3), activation='relu', padding='same',name='conv2_1')(pool1)                                                                    \n",
    "    conv2 = tf.keras.layers.Conv2D(64*2, (3, 3), activation='relu', padding='same',name='conv2_2')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(128*2, (3, 3), activation='relu', padding='same',name='conv3_1')(pool2)                                                                    \n",
    "    conv3 = tf.keras.layers.Conv2D(128*2, (3, 3), activation='relu', padding='same',name='conv3_2')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(256*2, (3, 3), activation='relu', padding='same',name='conv4_1')(pool3)                                                                    \n",
    "    conv4 = tf.keras.layers.Conv2D(256*2, (3, 3), activation='relu', padding='same',name='conv4_2')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),name='pool4')(conv4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(512*2, (3, 3), activation='relu', padding='same',name='conv5_1')(pool4)                                                                    \n",
    "    conv5 = tf.keras.layers.Conv2D(512*2, (3, 3), activation='relu', padding='same',name='conv5_2')(conv5)\n",
    "\n",
    "    up5 = tf.keras.layers.UpSampling2D(size=(2, 2),name='up5')(conv5)\n",
    "    up5_conv = tf.keras.layers.Conv2D(256*2,2,padding='same',name='up5_conv')(up5)\n",
    "    conv4_feature = tf.image.resize(conv4,  \n",
    "                                    (tf.shape(up5_conv)[1],tf.shape(up5_conv)[2]), \n",
    "                                     tf.image.ResizeMethod.NEAREST_NEIGHBOR,name='conv4_feature')\n",
    "    concat1 = tf.keras.layers.Concatenate(axis=-1,name='concat1')([up5_conv,conv4_feature])\n",
    "\n",
    "    conv6_1  = tf.keras.layers.Conv2D(256*2, (3, 3), activation='relu', padding='same',name='conv6_1')(concat1)                                                                    \n",
    "    conv6_2  = tf.keras.layers.Conv2D(256*2, (3, 3), activation='relu', padding='same',name='conv6_2')(conv6_1)\n",
    "\n",
    "    up6 = tf.keras.layers.UpSampling2D(size=(2, 2),name='up6')(conv6_2)\n",
    "    up6_conv = tf.keras.layers.Conv2D(128*2,2,padding='same',name='up6_conv')(up6)\n",
    "    conv3_feature = tf.image.resize(conv3, \n",
    "                                    (tf.shape(up6_conv)[1],tf.shape(up6_conv)[2]), \n",
    "                                     tf.image.ResizeMethod.NEAREST_NEIGHBOR,name='conv3_feature')\n",
    "    concat2 = tf.keras.layers.Concatenate(axis=-1,name='concat2')([up6_conv,conv3_feature])\n",
    "    \n",
    "    conv7_1  = tf.keras.layers.Conv2D(128*2, (3, 3), activation='relu', padding='same',name='conv7_1')(concat2) \n",
    "    conv7_2 = tf.keras.layers.Conv2D(128*2, (3, 3), activation='relu', padding='same',name='conv7_2')(conv7_1)\n",
    "\n",
    "    up7 = tf.keras.layers.UpSampling2D(size=(2, 2),name='up7')(conv7_2)\n",
    "    up7_conv = tf.keras.layers.Conv2D(64*2,2,padding='same',name='up7_conv')(up7)\n",
    "    conv2_feature = tf.image.resize(conv2,                                   \n",
    "                                    (tf.shape(up7_conv)[1],tf.shape(up7_conv)[2]), \n",
    "                                     tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "                                     name='conv2_feature')\n",
    "    concat3 = tf.keras.layers.Concatenate(axis=-1,name='concat3')([up7_conv,conv2_feature])\n",
    "    \n",
    "    conv8_1  = tf.keras.layers.Conv2D(64*2, (3, 3), activation='relu', padding='same',name='conv8_1')(concat3)\n",
    "    conv8_2 = tf.keras.layers.Conv2D(64*2, (3, 3), activation='relu', padding='same',name='conv8_2')(conv8_1)\n",
    "\n",
    "\n",
    "    up8 = tf.keras.layers.UpSampling2D(size=(2, 2),name='up8')(conv8_2)\n",
    "    up8_conv = tf.keras.layers.Conv2D(32*2,2,padding='same',name='up8_conv')(up8)\n",
    "    conv1_feature = tf.image.resize(conv1,                                   \n",
    "                                    (tf.shape(up8_conv)[1],tf.shape(up8_conv)[2]), \n",
    "                                     tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "                                     name='conv1_feature')\n",
    "    concat4 = tf.keras.layers.Concatenate(axis=-1,name='concat4')([up8_conv,conv1_feature])\n",
    "    \n",
    "    conv9_1  = tf.keras.layers.Conv2D(32*2, (3, 3), activation='relu', padding='same',name='conv9_1')(concat4)\n",
    "    conv9_2 = tf.keras.layers.Conv2D(32*2, (3, 3), activation='relu', padding='same',name='conv9_2')(conv9_1)\n",
    "\n",
    "    output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid',name='output')(conv9_2)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output,) \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(128,128)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "x_train =  np.arange(50,100, 50/(60*128*128)).reshape( 60,128, 128)   # 训练集输入数据\n",
    "y_train = x_train * 2 + 1 \n",
    "x_test = np.arange(0,50, 50/(60*128*128)).reshape( 60,128, 128)  # 测试集输入数据\n",
    "\n",
    "y_test = x_test * 2 + 1   # 测试集标签数据\n",
    "# print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 44s 25s/step - loss: 23490.4648 - mean_squared_error: 23490.4648 - val_loss: 3333.3284 - val_mean_squared_error: 3333.3284\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 39s 24s/step - loss: 23333.3184 - mean_squared_error: 23333.3184 - val_loss: 3333.3284 - val_mean_squared_error: 3333.3284\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 43s 27s/step - loss: 23333.3164 - mean_squared_error: 23333.3164 - val_loss: 3333.3284 - val_mean_squared_error: 3333.3284\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 50s 32s/step - loss: 23333.3164 - mean_squared_error: 23333.3164 - val_loss: 3333.3284 - val_mean_squared_error: 3333.3284\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 49s 29s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 52s 31s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 46s 28s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 56s 37s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 56s 32s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 53s 31s/step - loss: nan - mean_squared_error: nan - val_loss: nan - val_mean_squared_error: nan\n",
      "2/2 [==============================] - 12s 5s/step - loss: nan - mean_squared_error: nan\n",
      "Test accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "model = unet(128,128)\n",
    "# model.summary()             # 打印模型结构\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# 测试模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# 保存模型\n",
    "model.save('self_Unet.h5')\n",
    "\n",
    "# # 加载模型\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('self_Unet.h5')      \n",
    "\n",
    "# # 继续训练模型\n",
    "# model.fit(x_train, y_train, batch_size=32,epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于数据处理的ResNet      \n",
    "import tensorflow as tf                \n",
    "from d2l import tensorflow as d2l           \n",
    "class Residual(tf.keras.Model):  #@save                             \n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()                                                 \n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            num_channels, padding='same', kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            num_channels, kernel_size=3, padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(    \n",
    "                num_channels, kernel_size=1, strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization() \n",
    "        self.bn2 = tf.keras.layers.BatchNormalization() \n",
    "\n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return tf.keras.activations.relu(Y)\n",
    "\n",
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_residuals, first_block=False,\n",
    "                 **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []          \n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                self.residual_layers.append(\n",
    "                    Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual(num_channels))\n",
    "\n",
    "    def call(self, X):\n",
    "        # for layer in self.residual_layers.layers:\n",
    "         for layer in self.residual_layers:   \n",
    "             X =layer(X) \n",
    "         return X \n",
    "\n",
    "\n",
    "# 调整网络结构\n",
    "def net(lat_points, lon_ponints,channels=1, batch_size=60 ):    # 通道数为1 , 也就是只有降水这个变量. \n",
    "    # 定义网络结构 ==>   input_shape(batch_size , )      \n",
    "    return tf.keras.Sequential([                                           # batch_size 就是 all_time_points = 45\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=(lat_points, lon_ponints ,channels)),\n",
    "        #  strides  要小于  kernel_size    \n",
    "        # 可以这样理解,  channels 在实际物理中表示变量的个数.   \n",
    "        tf.keras.layers.BatchNormalization(),     \n",
    "        tf.keras.layers.Activation('relu'),             \n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same'),   # ?L????????????????????\n",
    "        ResnetBlock(64, 2, first_block=True),\n",
    "        ResnetBlock(128, 2),\n",
    "        ResnetBlock(256, 2),\n",
    "        ResnetBlock(512, 2),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Dense(lat_points*lon_ponints, activation='relu')   # softmax   , 不必分类.   \n",
    "    ])\n",
    "\n",
    "b1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n",
    "\n",
    "b2 = ResnetBlock(64, 2, first_block=True)\n",
    "b3 = ResnetBlock(128, 2)\n",
    "b4 = ResnetBlock(256, 2)\n",
    "b5 = ResnetBlock(512, 2)\n",
    "\n",
    "\n",
    "# 训练模型 \n",
    "# 自定义训练过程  ==> 暂时不用自定义训练过程, 直接使用fit方法\n",
    "# @tf.function\n",
    "# def train_step(inputs, labels, model, loss_fn, optimizer):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions = model(inputs, training=True)\n",
    "#         loss = loss_fn(labels, predictions)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# 编译模型\n",
    "# 损失函数和优化器\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()   # 用于分类\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()   # 用于回归\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)        # 使用Adam优化器\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['mean_squared_error']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例\n",
    "lat_pts, lon_pts, channels =  178, 156, 1  # 定义输入数据维度和通道数\n",
    "model = net(lat_pts, lon_pts, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看一下大小维度的变化  : \n",
    "X = tf.random.uniform(shape=(60, 178,156, 1))  \n",
    "for layer in net(178,156).layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集  \n",
    "X_test = test_data.PRECT.values   + np.random.normal(0,1,60*178*156).reshape(60,178,156)                             \n",
    "Y_test = test_data.PRECT.values   \n",
    "X_train=train_data.PRECT.values + np.random.normal(0,1,60*178*156).reshape(60,178,156)                     \n",
    "Y_train = train_data.PRECT.values\n",
    "\n",
    "X_train = X_train[..., np.newaxis]   # 进行升维     ,   因为 ResNet 网络的输入要求是 4D 张量，channel 我设置的事1 , 所以需要增加一个维度\n",
    "X_test = X_test[..., np.newaxis]\n",
    "Y_train = np.reshape(Y_train, (60,-1))\n",
    "Y_test = np.reshape(Y_test, (60,-1))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "batch_size = 32     # 也就是多少个时刻.   样本数    \n",
    "num_epochs = 10\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, Y_test)) \n",
    "\n",
    "# 绘制训练和验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])        # 验证集的损失值\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练和验证的准确率值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])   # 验证集的准确率值          \n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "# 绘制训练和验证的真实值和预测值的差异\n",
    "plt.plot(Y_test, label='real')\n",
    "plt.plot(model.predict(X_test), label='predict')\n",
    "plt.title('Model predict')          \n",
    "plt.legend()\n",
    "plt.show()              \n",
    "\n",
    "# 保存模型      \n",
    "model.save('ResNet.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
